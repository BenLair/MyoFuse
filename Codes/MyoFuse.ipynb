{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91571ad7-fa8d-428c-95f4-83fe1aabaf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from aicsimageio import AICSImage\n",
    "from tifffile import imwrite\n",
    "from cellpose import models\n",
    "import numpy as np\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.measure import regionprops\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from skimage.color import label2rgb\n",
    "from skimage.io import imsave\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from skimage.segmentation import find_boundaries\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.io import imsave\n",
    "from skimage import img_as_float\n",
    "from skimage import exposure\n",
    "\n",
    "if torch.cuda.is_available() is True:\n",
    "    try:\n",
    "        import cupy as cu\n",
    "        from cucim.skimage.morphology import dilation, disk\n",
    "        cuda = True\n",
    "    except ImportError:\n",
    "        from skimage.morphology import dilation, disk\n",
    "        cuda = False\n",
    "else:\n",
    "    from skimage.morphology import dilation, disk\n",
    "    cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8031639-6434-4496-91c0-13330929e5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER YOUR VALUES ##\n",
    "\n",
    "parent_directory = \"/path/to/your/folder/\" # Replace with the actual path\n",
    "cellpose_directory = \"/path/to/your/model\" # Replace with the actual path\n",
    "\n",
    "myotube_channel = 0 # Replace with the actual myotube channel \n",
    "nuclei_channel = 1 # Replace with the actual nuclei channel \n",
    "\n",
    "dia = 24 # Adjust this value depending on your images. Set it to 0 for Cellpose to automatically determine the best value.\n",
    "\n",
    "extension = (\".tif\", \".tiff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4457d332-e066-48ae-83fd-680a8061f77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMAGE SPLITTING ## \n",
    "\n",
    "# If necessary - Split Image into separate channels for processing\n",
    "\n",
    "# Define paths\n",
    "full_images_folder = os.path.join(parent_directory, \"Full Images\")\n",
    "myotube_folder = os.path.join(parent_directory, \"Images\")\n",
    "nuclei_folder = os.path.join(parent_directory, \"Nuclei\")\n",
    "predictions_output_dir = os.path.join(parent_directory, \"Predictions\")\n",
    "\n",
    "# Ensure output folders exists\n",
    "os.makedirs(myotube_folder, exist_ok=True)\n",
    "os.makedirs(nuclei_folder, exist_ok=True)\n",
    "os.makedirs(predictions_output_dir, exist_ok=True)\n",
    "\n",
    "# Process each image in \"Full Images\"\n",
    "if os.path.exists(full_images_folder):\n",
    "    for file in os.listdir(full_images_folder):\n",
    "        file_path = os.path.join(full_images_folder, file)\n",
    "\n",
    "        # Check if it's an image file\n",
    "        if file.lower().endswith((\".tiff\", \".tif\")):\n",
    "            image = imread(file_path)\n",
    "\n",
    "        elif file.lower().endswith((\".ome.tiff\", \".czi\")):\n",
    "            aics_image = AICSImage(file_path)\n",
    "            image = aics_image.data[0]  # Extract the data for the first scene\n",
    "            if image.ndim == 5:  # TCZYX\n",
    "                image = image[0, 0].transpose((1, 2, 0))\n",
    "            elif image.ndim == 4:  # CZYX\n",
    "                image = image[0].transpose((1, 2, 0))\n",
    "        else:\n",
    "            print(f\"Skipped {file}: unsupported file format.\")\n",
    "            continue\n",
    "\n",
    "        # Check if the image has at least 2 channels\n",
    "        if image.ndim == 3 and image.shape[2] >= 2:\n",
    "            myotube = image[myotube_channel, :, :]\n",
    "            nuclei = image[nuclei_channel, :, :]\n",
    "\n",
    "            # Save Myotube channel\n",
    "            myotube_save_path = os.path.join(myotube_folder, f\"{os.path.splitext(file)[0]}.tif\")\n",
    "            imsave(myotube_save_path, myotube.astype(np.uint16))\n",
    "\n",
    "            # Save Nuclei channel\n",
    "            nuclei_save_path = os.path.join(nuclei_folder, f\"{os.path.splitext(file)[0]}.tif\")\n",
    "            imsave(nuclei_save_path, nuclei.astype(np.uint16))\n",
    "\n",
    "            print(f\"Processed and saved channels for: {file}\")\n",
    "        else:\n",
    "            print(f\"Skipped {file}: not enough channels.\")\n",
    "else:\n",
    "    print(f\"The folder 'Full Images' does not exist in {parent_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cea099-2d46-4c0b-805e-d8852b6ecb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SEGMENTATION ##\n",
    "\n",
    "# List to store all image file paths\n",
    "image_files = []\n",
    "\n",
    "# Check if the \"Nuclei\" folder exists\n",
    "if os.path.exists(nuclei_folder):\n",
    "    for file in os.listdir(nuclei_folder):\n",
    "        file_path = os.path.join(nuclei_folder, file)\n",
    "        # Check if the file is an image (by extension)\n",
    "        if file.lower().endswith(( \".tiff\", \".tif\")):\n",
    "            image_files.append(file_path)\n",
    "else:\n",
    "    print(f\"The folder 'Nuclei' does not exist in {parent_directory}\")\n",
    "\n",
    "# Print the list of images\n",
    "for index, file in enumerate(image_files):\n",
    "    print(f\"{file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001799c0-1e46-4c92-8f54-815717671406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(file_path):\n",
    "    \n",
    "    # Load a single channel image\n",
    "    image = AICSImage(file_path).data[0][0] \n",
    "    return image\n",
    "\n",
    "def loop(file_path, parent_directory, diameter):\n",
    "    base_name = os.path.basename(file_path)\n",
    "    name_without_ext = os.path.splitext(base_name)[0]\n",
    "\n",
    "    # Ensure the \"Masks\" folder exists\n",
    "    masks_folder = os.path.join(parent_directory, \"Masks\")\n",
    "    if not os.path.exists(masks_folder):\n",
    "        os.makedirs(masks_folder)\n",
    "\n",
    "    # Empty GPU cache\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Load the image\n",
    "    img = load_image(file_path)\n",
    "\n",
    "    # Cellpose\n",
    "    model = models.CellposeModel(\n",
    "        gpu=True,\n",
    "        pretrained_model= cellpose_directory)\n",
    "    masks, flows, styles = model.eval(img, diameter, channels=[0, 0], normalize=True)\n",
    "\n",
    "     # Save the mask as compressed .tiff\n",
    "    if masks.max() > 0:\n",
    "        mask_save_path = os.path.join(masks_folder, name_without_ext + \".tif\")\n",
    "        imwrite(mask_save_path, masks.astype(np.uint16), compression='zlib')\n",
    "        print(f\"Mask saved: {mask_save_path}\")\n",
    "    else:\n",
    "        print(f\"No cells detected in {file_path}, no mask has been saved.\")\n",
    "\n",
    "    result = {\n",
    "        'image': file_path,\n",
    "        'diameter': diameter,\n",
    "        'cells count': np.max(masks)\n",
    "    }\n",
    "\n",
    "    # Empty GPU cache\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f13801c-97ef-4f8a-96f6-d0e57b94c557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all image files in the \"Nuclei\" folder\n",
    "image_files = [f for f in os.listdir(nuclei_folder) if f.lower().endswith(('.tif', '.tiff'))]\n",
    "\n",
    "# Process each image\n",
    "for file in image_files:\n",
    "    file_path = os.path.join(nuclei_folder, file)\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    result = loop(file_path, parent_directory, dia)                                                                                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389cc332-916f-40ce-84b6-4bdbfe14f47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLASSIFICATION ##\n",
    "\n",
    "def load_images_labels_props(parent_directory):\n",
    "    images_dir = os.path.join(parent_directory, \"Images\")\n",
    "    masks_dir = os.path.join(parent_directory, \"Masks\")\n",
    "\n",
    "    image_files = [f for f in os.listdir(images_dir) \n",
    "                   if f.lower().endswith(('.tif', '.tiff'))]\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    all_props = []\n",
    "\n",
    "    for img_file in image_files:\n",
    "        img_path = os.path.join(images_dir, img_file)\n",
    "        mask_path = os.path.join(masks_dir, img_file)\n",
    "\n",
    "        # Check if there is a corresponding mask\n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"No corresponding mask for {img_file}\")\n",
    "            continue\n",
    "\n",
    "        # Load Image and Mask\n",
    "        image_data = imread(img_path)\n",
    "        mask_data = imread(mask_path)\n",
    "\n",
    "        # Convert image to RGB\n",
    "        if len(image_data.shape) == 2:  # Check if grayscale\n",
    "            image_data = np.stack((image_data,) * 3, axis=-1)  # Convert to RGB\n",
    "\n",
    "        images.append(image_data)\n",
    "        labels.append(mask_data)\n",
    "\n",
    "        # Calculate regionprops properties\n",
    "        mask_label = mask_data.astype(np.int32, copy=False)\n",
    "        props = regionprops(mask_label)\n",
    "\n",
    "        all_props.append(props)\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels, all_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1343abe6-016f-4507-95bc-8739dcf87162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_norm(im):\n",
    "    im = (im - im.min()) / (im.max() - im.min())\n",
    "    return im\n",
    "\n",
    "class PredictionDataset(Dataset):\n",
    "    def __init__(self, image, labels, props, half_patch_size, device, config_dict):\n",
    "        if not isinstance(props, (list, tuple)):\n",
    "            raise ValueError(\"props must be a list or tuple, obtained from regionprops.\")\n",
    "        \n",
    "        self.props = props\n",
    "        self.image = image\n",
    "        self.labels = labels\n",
    "        self.half_patch_size = half_patch_size\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "        self.device = device\n",
    "        self.config_dict = config_dict\n",
    "        self.used_labels = [prop.label for prop in props]\n",
    "\n",
    "        pad_width = half_patch_size + 1\n",
    "        self.image = np.pad(image, ((pad_width, pad_width), (pad_width, pad_width), (0, 0)), mode=\"constant\")\n",
    "        self.labels = np.pad(labels, ((pad_width, pad_width), (pad_width, pad_width)), mode=\"constant\")\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        prop = self.props[index]\n",
    "        try:\n",
    "            cx, cy = map(int, prop.centroid)\n",
    "            cx += self.half_patch_size + 1\n",
    "            cy += self.half_patch_size + 1\n",
    "\n",
    "            xmin, xmax = cx - self.half_patch_size, cx + self.half_patch_size\n",
    "            ymin, ymax = cy - self.half_patch_size, cy + self.half_patch_size\n",
    "\n",
    "            imagette = self.image[xmin:xmax, ymin:ymax].copy()\n",
    "            maskette = self.labels[xmin:xmax, ymin:ymax].copy()\n",
    "            maskette[maskette != prop.label] = 0\n",
    "            maskette[maskette == prop.label] = 1\n",
    "\n",
    "            if json.loads(self.config_dict[\"options\"][\"dilation\"][\"dilate_mask\"].lower()):\n",
    "                str_el = disk(int(self.config_dict[\"options\"][\"dilation\"][\"str_element_size\"]))\n",
    "                maskette = dilation(maskette, str_el)\n",
    "                imagette *= maskette[:, :, None]\n",
    "\n",
    "            concat_image = np.zeros((imagette.shape[0], imagette.shape[1], imagette.shape[2] + 1))\n",
    "            concat_image[:, :, :-1] = imagette / imagette.max()\n",
    "            concat_image[:, :, -1] = maskette\n",
    "\n",
    "            return self.transform(concat_image.astype(\"float32\")).to(self.device)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing object {index}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d609347-6786-42ef-baf1-6948dfd53948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_colored_predictions(labels, predictions, used_labels, myotube_image_path, output_dir, image_name):\n",
    "    \n",
    "    # Load the myotube grayscale image\n",
    "    myotube_image = imread(myotube_image_path)\n",
    "    \n",
    "    # Adjust the contrast of the myotube image for better visibility\n",
    "    myotube_image = exposure.rescale_intensity(myotube_image, in_range='image', out_range=(0, 1))\n",
    "\n",
    "    # Convert the grayscale image to RGB (3 channels) for colorizing\n",
    "    myotube_rgb = np.stack((myotube_image,) * 3, axis=-1)\n",
    "\n",
    "    # Extract region properties from the label image\n",
    "    props = regionprops(labels)\n",
    "\n",
    "    # Extract the labels corresponding to the used regions\n",
    "    extracted_labels = [prop.label for prop in props if prop.label in used_labels]\n",
    "\n",
    "    # Ensure that the number of predictions matches the number of used labels\n",
    "    if len(predictions) != len(extracted_labels):\n",
    "        raise ValueError(f\"Mismatch: {len(predictions)} predictions for {len(extracted_labels)} labels\")\n",
    "\n",
    "    # Find the boundaries of each labeled region\n",
    "    boundaries = find_boundaries(labels, mode='inner')\n",
    "\n",
    "    # Define colors for each prediction class\n",
    "    color_0 = [1, 0, 0]  # Red for class 0\n",
    "    color_1 = [0, 1, 0]  # Green for class 1\n",
    "\n",
    "    # Apply colors to the boundaries of each region based on its prediction\n",
    "    for region_label, prediction in zip(extracted_labels, predictions):\n",
    "        # Create a mask for the current label's boundary\n",
    "        mask = (labels == region_label) & boundaries\n",
    "        if prediction == 0:\n",
    "            myotube_rgb[mask] = color_0  # Red for class 0\n",
    "        elif prediction == 1:\n",
    "            myotube_rgb[mask] = color_1  # Green for class 1\n",
    "\n",
    "    # Convert the RGB image to 8-bit format for saving\n",
    "    myotube_rgb = img_as_ubyte(myotube_rgb)\n",
    "\n",
    "    # Save the colorized image to the specified output directory\n",
    "    output_path = os.path.join(output_dir, f\"{image_name}_prediction.tif\")\n",
    "    imsave(output_path, myotube_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec5ee85-47a4-4a68-a032-536279fdb702",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(parent_directory, 'Svetlana', 'MyoFuse.pth')                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f537bf3-2916-43fb-912f-3335fff9bd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    images, labels, all_props = load_images_labels_props(parent_directory)\n",
    "    config_path = os.path.join(parent_directory, \"Svetlana\", \"Config.json\")\n",
    "    with open(config_path, 'r') as f:\n",
    "        config_dict = json.load(f)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    half_patch_size = 100\n",
    "\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model = checkpoint[\"model\"]\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_predictions = []\n",
    "    all_used_labels = []\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        print(f\"Processing image {i + 1}/{len(images)}\")\n",
    "        current_image = images[i]\n",
    "        current_label = labels[i]\n",
    "        current_props = all_props[i]\n",
    "\n",
    "        dataset = PredictionDataset(\n",
    "            image=current_image,\n",
    "            labels=current_label,\n",
    "            props=current_props,\n",
    "            half_patch_size=half_patch_size,\n",
    "            device=device,\n",
    "            config_dict=config_dict,\n",
    "        )\n",
    "        dataloader = DataLoader(dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "        used_labels = dataset.used_labels\n",
    "        image_predictions = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                if batch is None or batch.size(0) == 0:\n",
    "                    continue\n",
    "                batch = batch.to(device)\n",
    "                output = model(batch)\n",
    "                pred = output.argmax(dim=1)\n",
    "                image_predictions.extend(pred.cpu().numpy())\n",
    "\n",
    "        image_name = os.path.splitext(os.path.basename(image_files[i]))[0]\n",
    "        myotube_image_path = os.path.join(myotube_folder, f\"{image_name}.tif\")\n",
    "        save_colored_predictions(\n",
    "            labels=current_label,\n",
    "            predictions=image_predictions,\n",
    "            used_labels=used_labels,\n",
    "            myotube_image_path=myotube_image_path,\n",
    "            output_dir=predictions_output_dir,\n",
    "            image_name=image_name\n",
    "        )\n",
    "\n",
    "        all_predictions.append(image_predictions)\n",
    "        all_used_labels.append(used_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c40e5d-9a26-4d24-b11f-a20855608d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SAVE RESULTS ##\n",
    "\n",
    "# List to store statistics for each image\n",
    "prediction_data = []\n",
    "\n",
    "# Iterate over predictions for each image\n",
    "for i, predictions in enumerate(all_predictions):\n",
    "    num_ones = 0\n",
    "    num_zeros = 0\n",
    "\n",
    "    # Iterate over predictions in the image\n",
    "    for pred in predictions:\n",
    "        # Ensure that each `pred` is a valid array\n",
    "        if pred.size > 0:\n",
    "            num_ones += np.sum(pred == 1)  # Count pixels predicted as 1\n",
    "            num_zeros += np.sum(pred == 0)  # Count pixels predicted as 0\n",
    "\n",
    "    # Calculate the total number of labels\n",
    "    total_labels = num_ones + num_zeros\n",
    "    fusion_index = num_ones / total_labels * 100\n",
    "\n",
    "    # Add statistics to the list\n",
    "    prediction_data.append({\n",
    "        \"Image Name\": os.path.splitext(os.path.basename(image_files[i]))[0],\n",
    "        \"Total Number of Nuclei\": total_labels,\n",
    "        \"Nuclei In\": num_ones,\n",
    "        \"Nuclei Out\": num_zeros,\n",
    "        \"Fusion Index (%)\": fusion_index,\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "predictions_df = pd.DataFrame(prediction_data)\n",
    "\n",
    "# Export the DataFrame to an Excel file\n",
    "output_file_path = os.path.join(parent_directory, \"predictions_fusion_index.xlsx\")\n",
    "predictions_df.to_excel(output_file_path, index=False)\n",
    "\n",
    "# Display the DataFrame without index\n",
    "print(f\"\\nDataFrame exported to Excel file: {output_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:svetlana_env]",
   "language": "python",
   "name": "conda-env-svetlana_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
