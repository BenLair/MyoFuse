{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91571ad7-fa8d-428c-95f4-83fe1aabaf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORT LIBRARIES ##\n",
    "\n",
    "import os\n",
    "from aicsimageio import AICSImage\n",
    "from tifffile import imwrite\n",
    "from cellpose import models\n",
    "import numpy as np\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.measure import regionprops\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from skimage.color import label2rgb\n",
    "from skimage.io import imsave\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from skimage.segmentation import find_boundaries\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.io import imsave\n",
    "from skimage import img_as_float\n",
    "from skimage import exposure\n",
    "\n",
    "if torch.cuda.is_available() is True:\n",
    "    try:\n",
    "        import cupy as cu\n",
    "        from cucim.skimage.morphology import dilation, disk\n",
    "        cuda = True\n",
    "    except ImportError:\n",
    "        from skimage.morphology import dilation, disk\n",
    "        cuda = False\n",
    "else:\n",
    "    from skimage.morphology import dilation, disk\n",
    "    cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8031639-6434-4496-91c0-13330929e5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER YOUR VALUES ##\n",
    "\n",
    "parent_directory = \"/path/to/your/folder/\" # Replace with the actual path\n",
    "cellpose_directory = \"/path/to/your/model\" # Replace with the actual path\n",
    "\n",
    "myotube_channel = 0 # Replace with the actual myotube channel \n",
    "nuclei_channel = 1 # Replace with the actual nuclei channel \n",
    "\n",
    "dia = 24 # Adjust this value depending on your images. Set it to 0 for Cellpose to automatically determine the best value.\n",
    "\n",
    "extension = (\".tif\", \".tiff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4457d332-e066-48ae-83fd-680a8061f77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMAGE SPLITTING ## \n",
    "\n",
    "# If necessary - Split images into separate channels for processing\n",
    "\n",
    "# Define paths\n",
    "full_images_folder = os.path.join(parent_directory, \"Full Images\")\n",
    "myotube_folder = os.path.join(parent_directory, \"Images\")\n",
    "nuclei_folder = os.path.join(parent_directory, \"Nuclei\")\n",
    "predictions_output_dir = os.path.join(parent_directory, \"Predictions\")\n",
    "\n",
    "# Ensure output folders exists\n",
    "os.makedirs(myotube_folder, exist_ok=True)\n",
    "os.makedirs(nuclei_folder, exist_ok=True)\n",
    "os.makedirs(predictions_output_dir, exist_ok=True)\n",
    "\n",
    "# Process each image in \"Full Images\"\n",
    "if os.path.exists(full_images_folder):\n",
    "    for file in os.listdir(full_images_folder):\n",
    "        file_path = os.path.join(full_images_folder, file)\n",
    "\n",
    "        # Check if it's an image file\n",
    "        if file.lower().endswith((\".tiff\", \".tif\")):\n",
    "            image = imread(file_path)\n",
    "\n",
    "        elif file.lower().endswith((\".ome.tiff\", \".czi\")):\n",
    "            aics_image = AICSImage(file_path)\n",
    "            image = aics_image.data[0]  # Extract the data for the first scene\n",
    "            if image.ndim == 5:  # TCZYX\n",
    "                image = image[0, 0].transpose((1, 2, 0))\n",
    "            elif image.ndim == 4:  # CZYX\n",
    "                image = image[0].transpose((1, 2, 0))\n",
    "        else:\n",
    "            print(f\"Skipped {file}: unsupported file format.\")\n",
    "            continue\n",
    "\n",
    "        # Check if the image has at least 2 channels\n",
    "        if image.ndim == 3 and image.shape[2] >= 2:\n",
    "            myotube = image[myotube_channel, :, :]\n",
    "            nuclei = image[nuclei_channel, :, :]\n",
    "\n",
    "            # Save Myotube channel\n",
    "            myotube_save_path = os.path.join(myotube_folder, f\"{os.path.splitext(file)[0]}.tif\")\n",
    "            imsave(myotube_save_path, myotube.astype(np.uint16))\n",
    "\n",
    "            # Save Nuclei channel\n",
    "            nuclei_save_path = os.path.join(nuclei_folder, f\"{os.path.splitext(file)[0]}.tif\")\n",
    "            imsave(nuclei_save_path, nuclei.astype(np.uint16))\n",
    "\n",
    "            print(f\"Processed and saved channels for: {file}\")\n",
    "        else:\n",
    "            print(f\"Skipped {file}: not enough channels.\")\n",
    "else:\n",
    "    print(f\"The folder 'Full Images' does not exist in {parent_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cea099-2d46-4c0b-805e-d8852b6ecb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SEGMENTATION ##\n",
    "\n",
    "# List to store all image file paths\n",
    "image_files = []\n",
    "\n",
    "# Check if the \"Nuclei\" folder exists\n",
    "if os.path.exists(nuclei_folder):\n",
    "    for file in os.listdir(nuclei_folder):\n",
    "        file_path = os.path.join(nuclei_folder, file)\n",
    "        # Check if the file is an image\n",
    "        if file.lower().endswith(( \".tiff\", \".tif\")):\n",
    "            image_files.append(file_path)\n",
    "else:\n",
    "    print(f\"The folder 'Nuclei' does not exist in {parent_directory}\")\n",
    "\n",
    "# Print the list of images\n",
    "for index, file in enumerate(image_files):\n",
    "    print(f\"{file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001799c0-1e46-4c92-8f54-815717671406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(file_path):\n",
    "    \n",
    "    # Load a single channel image\n",
    "    image = AICSImage(file_path).data[0][0] \n",
    "    return image\n",
    "\n",
    "def loop(file_path, parent_directory, diameter):\n",
    "    base_name = os.path.basename(file_path)\n",
    "    name_without_ext = os.path.splitext(base_name)[0]\n",
    "\n",
    "    # Ensure the \"Masks\" folder exists\n",
    "    masks_folder = os.path.join(parent_directory, \"Masks\")\n",
    "    if not os.path.exists(masks_folder):\n",
    "        os.makedirs(masks_folder)\n",
    "\n",
    "    # Empty GPU cache\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Load the image\n",
    "    img = load_image(file_path)\n",
    "\n",
    "    # Cellpose\n",
    "    model = models.CellposeModel(\n",
    "        gpu=True,\n",
    "        pretrained_model= cellpose_directory)\n",
    "    masks, flows, styles = model.eval(img, diameter, channels=[0, 0], normalize=True)\n",
    "\n",
    "     # Save the mask as compressed .tiff\n",
    "    if masks.max() > 0:\n",
    "        mask_save_path = os.path.join(masks_folder, name_without_ext + \".tif\")\n",
    "        imwrite(mask_save_path, masks.astype(np.uint16), compression='zlib')\n",
    "        print(f\"Mask saved: {mask_save_path}\")\n",
    "    else:\n",
    "        print(f\"No cells detected in {file_path}, no mask has been saved.\")\n",
    "\n",
    "    result = {\n",
    "        'image': file_path,\n",
    "        'diameter': diameter,\n",
    "        'cells count': np.max(masks)\n",
    "    }\n",
    "\n",
    "    # Empty GPU cache\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f13801c-97ef-4f8a-96f6-d0e57b94c557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all image files in the \"Nuclei\" folder\n",
    "image_files = [f for f in os.listdir(nuclei_folder) if f.lower().endswith(('.tif', '.tiff'))]\n",
    "\n",
    "# Process each image\n",
    "for file in image_files:\n",
    "    file_path = os.path.join(nuclei_folder, file)\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    result = loop(file_path, parent_directory, dia)                                                                                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec5ee85-47a4-4a68-a032-536279fdb702",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLASSIFICATION ##\n",
    "\n",
    "model_path = os.path.join(parent_directory, 'Svetlana', 'MyoFuse.pth') # Replace with the actual path                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389cc332-916f-40ce-84b6-4bdbfe14f47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_labels_props(parent_directory):\n",
    "    # Define the directories for images and masks\n",
    "    images_dir = os.path.join(parent_directory, \"Images\")\n",
    "    masks_dir = os.path.join(parent_directory, \"Masks\")\n",
    "\n",
    "    # List all the .tif or .tiff files in images_dir\n",
    "    image_files = [f for f in os.listdir(images_dir) \n",
    "                   if f.lower().endswith(('.tif', '.tiff'))]\n",
    "\n",
    "    # Prepare empty lists to store images, labels (masks), and region properties\n",
    "    images = []\n",
    "    labels = []\n",
    "    all_props = []\n",
    "\n",
    "    # Loop through each image file found\n",
    "    for img_file in image_files:\n",
    "        # Build the full path to the image and the corresponding mask\n",
    "        img_path = os.path.join(images_dir, img_file)\n",
    "        mask_path = os.path.join(masks_dir, img_file)\n",
    "\n",
    "        # If there's no corresponding mask file, skip this image\n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"No corresponding mask for {img_file}\")\n",
    "            continue\n",
    "\n",
    "        # Load the image and mask from disk\n",
    "        image_data = imread(img_path)\n",
    "        mask_data = imread(mask_path)\n",
    "\n",
    "        # If the image is grayscale (2D array), convert it to an RGB image\n",
    "        if len(image_data.shape) == 2:\n",
    "            image_data = np.stack((image_data,) * 3, axis=-1)\n",
    "\n",
    "        # Add the image and its mask to the respective lists\n",
    "        images.append(image_data)\n",
    "        labels.append(mask_data)\n",
    "\n",
    "        # Convert the mask data to a suitable integer type for regionprops\n",
    "        mask_label = mask_data.astype(np.int32, copy=False)\n",
    "\n",
    "        # Compute region properties for the labeled mask\n",
    "        props = regionprops(mask_label)\n",
    "        all_props.append(props)\n",
    "\n",
    "    # Convert the lists of images and labels to NumPy arrays\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels, all_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1343abe6-016f-4507-95bc-8739dcf87162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_norm(im):\n",
    "    im = (im - im.min()) / (im.max() - im.min())\n",
    "    return im\n",
    "\n",
    "class PredictionDataset(Dataset):\n",
    "    def __init__(self, image, labels, props, half_patch_size, device, config_dict):\n",
    "\n",
    "        # Validate that props is a list or tuple\n",
    "        if not isinstance(props, (list, tuple)):\n",
    "            raise ValueError(\"props must be a list or tuple, obtained from regionprops.\")\n",
    "        \n",
    "        # Store constructor arguments as attributes\n",
    "        self.props = props\n",
    "        self.image = image\n",
    "        self.labels = labels\n",
    "        self.half_patch_size = half_patch_size\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "        self.device = device\n",
    "        self.config_dict = config_dict\n",
    "        self.used_labels = [prop.label for prop in props]\n",
    "        \n",
    "        # We pad the image and labels to ensure that when we extract patches\n",
    "        # near boundaries, we don't go out of range. The padding size is at \n",
    "        # least 'half_patch_size + 1' in each spatial dimension.\n",
    "        pad_width = half_patch_size + 1\n",
    "\n",
    "        # Pad the image (height, width, channels)\n",
    "        self.image = np.pad(image, ((pad_width, pad_width), (pad_width, pad_width), (0, 0)), mode=\"constant\")\n",
    "\n",
    "        # Pad the labels (height, width)\n",
    "        self.labels = np.pad(labels, ((pad_width, pad_width), (pad_width, pad_width)), mode=\"constant\")\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        prop = self.props[index] # Retrieve the RegionProperties object\n",
    "        try:\n",
    "            # Obtain the integer centroid coordinates (cx, cy).\n",
    "            # Note: skimage regionprops returns centroid as (row, col), so we map them to int.\n",
    "            cx, cy = map(int, prop.centroid)\n",
    "\n",
    "            # Adjust centroid to account for the padding we added above.\n",
    "            cx += self.half_patch_size + 1\n",
    "            cy += self.half_patch_size + 1\n",
    "           \n",
    "            # Calculate the bounding box for the patch\n",
    "            xmin, xmax = cx - self.half_patch_size, cx + self.half_patch_size\n",
    "            ymin, ymax = cy - self.half_patch_size, cy + self.half_patch_size\n",
    "\n",
    "            # Extract the patch (imagette) from the padded image\n",
    "            imagette = self.image[xmin:xmax, ymin:ymax].copy()\n",
    "\n",
    "            # Extract the patch (maskette) from the padded labels\n",
    "            maskette = self.labels[xmin:xmax, ymin:ymax].copy()\n",
    "\n",
    "            # Binarize the mask for the current prop:\n",
    "            # Pixels matching 'prop.label' are set to 1, everything else is set to 0.\n",
    "            maskette[maskette != prop.label] = 0\n",
    "            maskette[maskette == prop.label] = 1\n",
    "\n",
    "            # Check the config_dict to see if dilation is enabled\n",
    "            # If enabled, dilate the mask by a structural element of given size\n",
    "            if json.loads(self.config_dict[\"options\"][\"dilation\"][\"dilate_mask\"].lower()):\n",
    "                str_el = disk(int(self.config_dict[\"options\"][\"dilation\"][\"str_element_size\"]))\n",
    "                maskette = dilation(maskette, str_el)\n",
    "\n",
    "                # Multiply the image patch by the dilated mask so only \n",
    "                # the region around the object is retained.\n",
    "                imagette *= maskette[:, :, None]\n",
    "\n",
    "            # Create a new array with one extra channel (mask)\n",
    "            # The original patch might be multi-channel. We add the mask as an extra channel.\n",
    "            concat_image = np.zeros((imagette.shape[0], imagette.shape[1], imagette.shape[2] + 1))\n",
    "\n",
    "            # Normalize the image patch and place in the first channels\n",
    "            concat_image[:, :, :-1] = imagette / imagette.max()\n",
    "\n",
    "            # Place the mask in the last channel\n",
    "            concat_image[:, :, -1] = maskette\n",
    "\n",
    "            # Convert to float32, transform to Torch tensor, and move to device\n",
    "            return self.transform(concat_image.astype(\"float32\")).to(self.device)\n",
    "\n",
    "        except Exception as e:\n",
    "            \n",
    "            # If an error occurs, print it and return None so we skip this index\n",
    "            print(f\"Error processing object {index}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d609347-6786-42ef-baf1-6948dfd53948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_colored_predictions(labels, predictions, used_labels, myotube_image_path, output_dir, image_name):\n",
    "    \n",
    "    # Load the myotube grayscale image\n",
    "    myotube_image = imread(myotube_image_path)\n",
    "    \n",
    "    # Adjust the contrast of the myotube image for better visibility\n",
    "    myotube_image = exposure.rescale_intensity(myotube_image, in_range='image', out_range=(0, 1))\n",
    "\n",
    "    # Convert the grayscale image to RGB (3 channels) for colorizing\n",
    "    myotube_rgb = np.stack((myotube_image,) * 3, axis=-1)\n",
    "\n",
    "    # Extract region properties from the label image\n",
    "    props = regionprops(labels)\n",
    "\n",
    "    # Extract the labels corresponding to the used regions\n",
    "    extracted_labels = [prop.label for prop in props if prop.label in used_labels]\n",
    "\n",
    "    # Ensure that the number of predictions matches the number of used labels\n",
    "    if len(predictions) != len(extracted_labels):\n",
    "        raise ValueError(f\"Mismatch: {len(predictions)} predictions for {len(extracted_labels)} labels\")\n",
    "\n",
    "    # Find the boundaries of each labeled region\n",
    "    boundaries = find_boundaries(labels, mode='inner')\n",
    "\n",
    "    # Define colors for each prediction class\n",
    "    color_0 = [1, 0, 0]  # Red for class 0\n",
    "    color_1 = [0, 1, 0]  # Green for class 1\n",
    "\n",
    "    # Apply colors to the boundaries of each region based on its prediction\n",
    "    for region_label, prediction in zip(extracted_labels, predictions):\n",
    "        # Create a mask for the current label's boundary\n",
    "        mask = (labels == region_label) & boundaries\n",
    "        if prediction == 0:\n",
    "            myotube_rgb[mask] = color_0  # Red for class 0\n",
    "        elif prediction == 1:\n",
    "            myotube_rgb[mask] = color_1  # Green for class 1\n",
    "\n",
    "    # Convert the RGB image to 8-bit format for saving\n",
    "    myotube_rgb = img_as_ubyte(myotube_rgb)\n",
    "\n",
    "    # Save the colorized image to the specified output directory\n",
    "    output_path = os.path.join(output_dir, f\"{image_name}_prediction.tif\")\n",
    "    imsave(output_path, myotube_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f537bf3-2916-43fb-912f-3335fff9bd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load images, labels, and properties (props) from the specified parent_directory\n",
    "    images, labels, all_props = load_images_labels_props(parent_directory)\n",
    "\n",
    "    # Define the path to the \"Config.json\" file\n",
    "    config_path = os.path.join(parent_directory, \"Svetlana\", \"Config.json\")\n",
    "\n",
    "    # Read and parse the configuration file as a Python dictionary\n",
    "    with open(config_path, 'r') as f:\n",
    "        config_dict = json.load(f)\n",
    "\n",
    "    # Select the device: use GPU (cuda) if available, otherwise use CPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Define the half-patch size (used in the PredictionDataset)\n",
    "    half_patch_size = 100\n",
    "\n",
    "    # Load the PyTorch checkpoint (model state), mapped to the selected device\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model = checkpoint[\"model\"]\n",
    "\n",
    "    # Move the model to the appropriate device and set it to evaluation mode\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Lists to collect all predictions and the labels used\n",
    "    all_predictions = []\n",
    "    all_used_labels = []\n",
    "\n",
    "    # Process each image in the dataset\n",
    "    for i in range(len(images)):\n",
    "        print(f\"Processing image {i + 1}/{len(images)}\")\n",
    "        current_image = images[i]\n",
    "        current_label = labels[i]\n",
    "        current_props = all_props[i]\n",
    "\n",
    "        # Create the custom PredictionDataset for the current image\n",
    "        dataset = PredictionDataset(\n",
    "            image=current_image,\n",
    "            labels=current_label,\n",
    "            props=current_props,\n",
    "            half_patch_size=half_patch_size,\n",
    "            device=device,\n",
    "            config_dict=config_dict,\n",
    "        )\n",
    "\n",
    "        # Create a DataLoader to batch the data\n",
    "        dataloader = DataLoader(dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "        # Retrieve the label values used in this dataset\n",
    "        used_labels = dataset.used_labels\n",
    "        image_predictions = []\n",
    "\n",
    "        # Disable gradient computation for inference\n",
    "        with torch.no_grad():\n",
    "            # Iterate through the DataLoader\n",
    "            for batch in dataloader:\n",
    "                # If the batch is None or empty, continue to the next batch\n",
    "                if batch is None or batch.size(0) == 0:\n",
    "                    continue\n",
    "\n",
    "                # Move the batch to the device\n",
    "                batch = batch.to(device)\n",
    "                \n",
    "                # Forward pass: compute the model output\n",
    "                output = model(batch)\n",
    "                \n",
    "                # Extract the predicted class for each patch in the batch\n",
    "                pred = output.argmax(dim=1)\n",
    "                \n",
    "                # Append the predictions to the list (moved back to CPU)\n",
    "                image_predictions.extend(pred.cpu().numpy())\n",
    "\n",
    "        # Extract the image name (without extension) for saving outputs\n",
    "        image_name = os.path.splitext(os.path.basename(image_files[i]))[0]\n",
    "\n",
    "        # Define the path for a \"myotube\" image version (if relevant)\n",
    "        myotube_image_path = os.path.join(myotube_folder, f\"{image_name}.tif\")\n",
    "\n",
    "        # Save colored predictions based on the model output\n",
    "        save_colored_predictions(\n",
    "            labels=current_label,\n",
    "            predictions=image_predictions,\n",
    "            used_labels=used_labels,\n",
    "            myotube_image_path=myotube_image_path,\n",
    "            output_dir=predictions_output_dir,\n",
    "            image_name=image_name\n",
    "        )\n",
    "\n",
    "        # Store the predictions and used labels for future reference\n",
    "        all_predictions.append(image_predictions)\n",
    "        all_used_labels.append(used_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c40e5d-9a26-4d24-b11f-a20855608d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SAVE RESULTS ##\n",
    "\n",
    "# List to store statistics for each image\n",
    "prediction_data = []\n",
    "\n",
    "# Iterate over predictions for each image\n",
    "for i, predictions in enumerate(all_predictions):\n",
    "    num_ones = 0\n",
    "    num_zeros = 0\n",
    "\n",
    "    # Iterate over predictions in the image\n",
    "    for pred in predictions:\n",
    "        # Ensure that each `pred` is a valid array\n",
    "        if pred.size > 0:\n",
    "            num_ones += np.sum(pred == 1)  # Count pixels predicted as 1\n",
    "            num_zeros += np.sum(pred == 0)  # Count pixels predicted as 0\n",
    "\n",
    "    # Calculate the total number of labels\n",
    "    total_labels = num_ones + num_zeros\n",
    "    fusion_index = num_ones / total_labels * 100\n",
    "\n",
    "    # Add statistics to the list\n",
    "    prediction_data.append({\n",
    "        \"Image Name\": os.path.splitext(os.path.basename(image_files[i]))[0],\n",
    "        \"Total Number of Nuclei\": total_labels,\n",
    "        \"Nuclei In\": num_ones,\n",
    "        \"Nuclei Out\": num_zeros,\n",
    "        \"Fusion Index (%)\": fusion_index,\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "predictions_df = pd.DataFrame(prediction_data)\n",
    "\n",
    "# Export the DataFrame to an Excel file\n",
    "output_file_path = os.path.join(parent_directory, \"predictions_fusion_index.xlsx\")\n",
    "predictions_df.to_excel(output_file_path, index=False)\n",
    "\n",
    "# Display the DataFrame without index\n",
    "print(f\"\\nDataFrame exported to Excel file: {output_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
