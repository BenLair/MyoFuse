{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1256d2c4-aaca-4297-bbf0-2b66b4685c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "display(HTML('''\n",
    "<style>\n",
    "#rendered_cells {\n",
    "    position: relative !important;\n",
    "    left: auto !important;\n",
    "    right: auto !important;\n",
    "    top: auto !important;\n",
    "    bottom: auto !important;\n",
    "\n",
    "    display: flex !important;\n",
    "    flex-direction: column !important;\n",
    "    align-items: center !important;\n",
    "    justify-content: flex-start !important; /* ou center si vous voulez centrer verticalement */\n",
    "    \n",
    "    width: 100% !important;\n",
    "    max-width: 1500 !important;\n",
    "    margin: 0 auto !important;\n",
    "    text-align: center !important;\n",
    "}\n",
    "</style>\n",
    "'''))\n",
    "\n",
    "display(HTML('''\n",
    "<style>\n",
    ".jp-OutputArea pre, .output_subarea pre {\n",
    "    text-align: center !important;\n",
    "}\n",
    "</style>\n",
    "'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91571ad7-fa8d-428c-95f4-83fe1aabaf23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce1b2721e9564a3297bfa31a54b42170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<h1 style='text-align:center'>Welcome to MyoFuse 1.0.0</h1>\"), VBox(children=(VBox(â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## IMPORT LIBRARIES ##\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from cellpose import models\n",
    "from aicsimageio import AICSImage\n",
    "from tifffile import imwrite \n",
    "from skimage.io import imread, imsave\n",
    "from skimage.measure import label\n",
    "from skimage.morphology import dilation, disk\n",
    "from skimage.transform import resize\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.segmentation import find_boundaries\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from scipy import ndimage\n",
    "import warnings\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipyfilechooser import FileChooser\n",
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "if torch.cuda.is_available() is True:\n",
    "    try:\n",
    "        import cupy as cu\n",
    "        from cucim.skimage.morphology import dilation, disk\n",
    "        cuda = True\n",
    "    except ImportError:\n",
    "        from skimage.morphology import dilation, disk\n",
    "        cuda = False\n",
    "else:\n",
    "    from skimage.morphology import dilation, disk\n",
    "    cuda = False\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#### FUNCTIONS ####\n",
    "\n",
    "def load_checkpoint(filename):\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r') as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "def save_checkpoint(filename, data):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "def reset_checkpoints():\n",
    "    cp_files = [\"channel_split_checkpoint.json\", \"segmentation_checkpoint.json\", \"classification_checkpoint.json\"]\n",
    "    for cp in cp_files:\n",
    "        if os.path.exists(cp):\n",
    "            os.remove(cp)\n",
    "\n",
    "def normalize_image(image, percentile_max, nbins=512, smoothing=2):\n",
    "    \n",
    "     # Extract non-0 pixels\n",
    "    nonzero_pixels = image[image > 0]\n",
    "    if nonzero_pixels.size == 0:\n",
    "        return image \n",
    "\n",
    "    # Compute CDF\n",
    "    hist, bin_edges = np.histogram(nonzero_pixels, bins=nbins)\n",
    "    cdf = np.cumsum(hist)\n",
    "    cdf = cdf / cdf[-1]  # normalize between 0 and 1\n",
    "    diff = np.diff(cdf)  # size nbins-1\n",
    "    secdiff = np.diff(diff)  # size nbins-2\n",
    "\n",
    "    # Smoothing of second derivative\n",
    "    if smoothing > 1:\n",
    "        kernel = np.ones(smoothing) / smoothing\n",
    "        secdiff_smooth = np.convolve(secdiff, kernel, mode='same')\n",
    "    else:\n",
    "        secdiff_smooth = secdiff\n",
    "\n",
    "    # Search for maximum\n",
    "    idx_knee = np.argmax(secdiff_smooth)\n",
    "    idx_knee_in_cdf = idx_knee + 1 \n",
    "\n",
    "    if idx_knee_in_cdf < 0 or idx_knee_in_cdf >= len(bin_edges):\n",
    "        idx_knee_in_cdf = 0  # fallback if out of boundaries\n",
    "\n",
    "    # Set new min threshold\n",
    "    new_min = bin_edges[idx_knee_in_cdf]\n",
    "\n",
    "    # Set high threshold\n",
    "    max_val = np.percentile(nonzero_pixels, percentile_max)\n",
    "\n",
    "    # Normalize between 0 and 1\n",
    "    norm_image = np.zeros_like(image, dtype=np.float32)\n",
    "\n",
    "    image_clipped = np.clip(image, new_min, max_val)\n",
    "    denom = (max_val - new_min) if (max_val > new_min) else 1e-9\n",
    "\n",
    "    mask = (image_clipped >= new_min)\n",
    "    norm_image[mask] = (image_clipped[mask] - new_min) / denom\n",
    "\n",
    "    norm_image = np.clip(norm_image, 0, 1)\n",
    "    \n",
    "    return norm_image\n",
    "def max_to_one(im):\n",
    "    \n",
    "    im = im / im.max()\n",
    "\n",
    "    return im\n",
    "    \n",
    "## Collect label centroids\n",
    "\n",
    "def compute_label_centroids(label_image):\n",
    "    \n",
    "    label_image = label_image.astype(np.int32, copy=False)\n",
    "    labels_unique = np.unique(label_image)\n",
    "    labels_unique = labels_unique[labels_unique != 0]\n",
    "\n",
    "    weights = np.ones_like(label_image, dtype=np.float32)\n",
    "    cm = ndimage.center_of_mass(weights, labels=label_image, index=labels_unique)\n",
    "\n",
    "    return labels_unique, cm\n",
    "\n",
    "## Prediction functions\n",
    "\n",
    "class PredictionDataset(Dataset):\n",
    "    \"\"\"\n",
    "      prop.centroid = (row, col)  =>  cx = row, cy = col  \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image, labels, label_ids, centroids, half_patch_size, device, config_dict):\n",
    "        super().__init__()\n",
    "        self.image = image\n",
    "        self.labels = labels\n",
    "        self.label_ids = label_ids\n",
    "        self.centroids = centroids\n",
    "        self.half_patch_size = half_patch_size\n",
    "        self.device = device\n",
    "        self.config_dict = config_dict\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "        pad = half_patch_size + 1\n",
    "\n",
    "        self.image = np.pad(\n",
    "            self.image,\n",
    "            ((pad, pad), (pad, pad), (0, 0)),\n",
    "            mode=\"constant\"\n",
    "        )\n",
    "        if self.labels.dtype != np.int32:\n",
    "            self.labels = self.labels.astype(np.int32, copy=False)\n",
    "        self.labels = np.pad(\n",
    "            self.labels,\n",
    "            ((pad, pad), (pad, pad)),\n",
    "            mode=\"constant\"\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "           \n",
    "            row, col = self.centroids[idx] \n",
    "            cx = int(row)\n",
    "            cy = int(col)\n",
    "            cx += self.half_patch_size + 1\n",
    "            cy += self.half_patch_size + 1\n",
    "            hps = self.half_patch_size\n",
    "            xmin, xmax = cx - hps, cx + hps\n",
    "            ymin, ymax = cy - hps, cy + hps\n",
    "\n",
    "            # Extract patch\n",
    "            patch_img = self.image[xmin:xmax, ymin:ymax, :].copy()\n",
    "            patch_mask = self.labels[xmin:xmax, ymin:ymax].copy()\n",
    "\n",
    "            label_id = self.label_ids[idx]\n",
    "\n",
    "            # Normalize\n",
    "            patch_img = max_to_one(patch_img)\n",
    "\n",
    "            # Binarize\n",
    "            patch_mask[patch_mask != label_id] = 0\n",
    "            patch_mask[patch_mask == label_id] = 1\n",
    "\n",
    "            # Dilation if stated in the config file\n",
    "            do_dilate = json.loads(self.config_dict[\"options\"][\"dilation\"][\"dilate_mask\"].lower())\n",
    "            if do_dilate:\n",
    "                se_size = int(self.config_dict[\"options\"][\"dilation\"][\"str_element_size\"])\n",
    "                strel = disk(se_size)\n",
    "                patch_mask = dilation(patch_mask, strel)\n",
    "                patch_img *= patch_mask[..., None]\n",
    "\n",
    "            # Mask concatenation as 4th channel\n",
    "            out = np.zeros((patch_img.shape[0], patch_img.shape[1], 4), dtype=np.float32)\n",
    "            out[..., :3] = patch_img\n",
    "            out[..., 3] = patch_mask\n",
    "\n",
    "            # Transformation to (C, H, W) + Tensor\n",
    "            out = self.transform(out)\n",
    "            return out.to(self.device)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Dataset] Erreur index {idx} : {e}\")\n",
    "            return None\n",
    "pass\n",
    "\n",
    "## Save prediction image\n",
    "\n",
    "def save_colored_predictions_downsample(\n",
    "    labels, \n",
    "    predictions, \n",
    "    used_labels, \n",
    "    myotube_image, \n",
    "    output_path, \n",
    "    factor=1\n",
    "):\n",
    "    if myotube_image.ndim == 3 and myotube_image.shape[2] == 3:\n",
    "        myotube_image = np.mean(myotube_image, axis=2)\n",
    "    H, W = myotube_image.shape\n",
    "\n",
    "    newH, newW = H//factor, W//factor\n",
    "    myotube_ds = resize(myotube_image, (newH, newW),\n",
    "                        preserve_range=True,\n",
    "                        anti_aliasing=True)\n",
    "\n",
    "    myotube_rgb = np.stack([myotube_ds]*3, axis=-1)\n",
    "\n",
    "    boundaries = find_boundaries(labels, mode='inner')\n",
    "    boundary_labels = labels.copy()\n",
    "    boundary_labels[~boundaries] = 0\n",
    "\n",
    "    if len(predictions) != len(used_labels):\n",
    "        raise ValueError(\"Number of predictions != Number of labels.\")\n",
    "    label_to_pred = dict(zip(used_labels, predictions))\n",
    "\n",
    "    color_0 = [1.0, 0.0, 0.0]  # Rouge = Nuclei Out\n",
    "    color_1 = [0.0, 1.0, 0.0]  # Vert = Nuclei In\n",
    "\n",
    "    coords = np.column_stack(np.nonzero(boundary_labels))\n",
    "    for (y, x) in coords:\n",
    "        lb = boundary_labels[y, x]\n",
    "        pred_class = label_to_pred.get(lb, None)\n",
    "        if pred_class is not None:\n",
    "            yd = y // factor\n",
    "            xd = x // factor\n",
    "            if yd < newH and xd < newW:\n",
    "                if pred_class == 0:\n",
    "                    myotube_rgb[yd, xd] = color_0\n",
    "                else:\n",
    "                    myotube_rgb[yd, xd] = color_1\n",
    "    myotube_rgb_8 = img_as_ubyte(myotube_rgb)\n",
    "    imsave(output_path, myotube_rgb_8)\n",
    "    pass\n",
    "\n",
    "#### ANALYSIS ####\n",
    "\n",
    "def run_entire_analysis(\n",
    "    myotube_channel, nuclei_channel, dia, percentile_max,\n",
    "    half_patch_size, batch_size, split_images, run_segmentation, seg_device, run_classification, class_device, save_normalization, save_prediction, downsampling_factor,\n",
    "    parent_directory_value, seg_directory_value, class_directory_value\n",
    "):\n",
    "    \n",
    "    myotube_folder = os.path.join(parent_directory_value, \"Images\")\n",
    "    nuclei_folder = os.path.join(parent_directory_value, \"Nuclei\")\n",
    "    masks_folder = os.path.join(parent_directory_value, \"Masks\")\n",
    "    predictions_output_dir = os.path.join(parent_directory_value, \"Predictions\")\n",
    "    class_dir = os.path.dirname(class_directory_value)\n",
    "    config_path = os.path.join(class_dir, \"Config.json\")\n",
    "    log_folder = os.path.join(parent_directory_value, \"Log\")\n",
    "    norm_dir = os.path.join(parent_directory_value, \"Normalized_images\")\n",
    "    \n",
    "    os.makedirs(log_folder, exist_ok=True)\n",
    "    extension = (\".tif\", \".tiff\")\n",
    "    \n",
    "## IMAGE SPLITTING ##\n",
    "    \n",
    "    if split_images:\n",
    "\n",
    "        os.makedirs(myotube_folder, exist_ok=True)\n",
    "        os.makedirs(nuclei_folder, exist_ok=True)\n",
    "        \n",
    "        channel_checkpoint_file = os.path.join(log_folder,\"channel_split_checkpoint.json\")\n",
    "        channel_checkpoint = load_checkpoint(channel_checkpoint_file)\n",
    "        processed_channel_files = channel_checkpoint.get(\"processed_files\", [])\n",
    "\n",
    "        display(Markdown(\"## CHANNEL SPLITTING ##\"))\n",
    "        file_list = [f for f in os.listdir(parent_directory_value) if f.lower().endswith(('.tif', '.tiff', '.ome.tiff', '.czi'))]\n",
    "        total_files = len(file_list)\n",
    "        \n",
    "        channel_progress = widgets.IntProgress(min=0, max=total_files, description='Progress ', style={'description_width': 'initial'}, layout=widgets.Layout(width='30%'))\n",
    "        display(widgets.HBox([channel_progress], layout=widgets.Layout(justify_content='center')))\n",
    "    \n",
    "        if not os.path.exists(parent_directory_value):\n",
    "            print(f\"n/No images found in {parent_directory_value}\")\n",
    "        else:\n",
    "            for idx, file in enumerate(file_list, 1):\n",
    "                if file in processed_channel_files:\n",
    "                    print(f\"n/{file} already processed.\")\n",
    "                    continue\n",
    "    \n",
    "                file_path = os.path.join(parent_directory_value, file)\n",
    "                try:\n",
    "                    if file.lower().endswith((\".tiff\", \".tif\")):\n",
    "                        image = imread(file_path)\n",
    "                    elif file.lower().endswith((\".ome.tiff\", \".czi\")):\n",
    "                        aics_image = AICSImage(file_path, reconstruct_mosaic=False)\n",
    "                        image = aics_image.data[0]\n",
    "                        print(image.shape)\n",
    "                        if image.ndim == 5:\n",
    "                            image = image[0, 0].transpose((1, 2, 0))\n",
    "                        elif image.ndim == 4:\n",
    "                            image = image[0].transpose((1, 2, 0))\n",
    "                        else:\n",
    "                            continue\n",
    "                    else:\n",
    "                        continue\n",
    "    \n",
    "                    # Extract and save channels\n",
    "                    if image.ndim == 3 and image.shape[2] >= 2:\n",
    "                        myotube = image[myotube_channel, :, :]\n",
    "                        nuclei = image[nuclei_channel, :, :]\n",
    "                        myotube_save_path = os.path.join(myotube_folder, f\"{os.path.splitext(file)[0]}.tif\")\n",
    "                        imsave(myotube_save_path, myotube.astype(np.uint16))\n",
    "                        nuclei_save_path = os.path.join(nuclei_folder, f\"{os.path.splitext(file)[0]}.tif\")\n",
    "                        imsave(nuclei_save_path, nuclei.astype(np.uint16))\n",
    "                        print(f\"Processed and saved channels for: {file}\")\n",
    "                    else:\n",
    "                        print(f\"Skipped {file}: not enough channels.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed processing {file}: {e}\")\n",
    "                    continue  # Move on to next file\n",
    "                    \n",
    "                # Update checkpoint\n",
    "                processed_channel_files.append(file)\n",
    "                channel_checkpoint[\"processed_files\"] = processed_channel_files\n",
    "                save_checkpoint(channel_checkpoint_file, channel_checkpoint)\n",
    "                channel_progress.value = idx\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "## SEGMENTATION ##\n",
    "\n",
    "    if run_segmentation: \n",
    "\n",
    "        os.makedirs(masks_folder, exist_ok=True)\n",
    "\n",
    "        if seg_device == \"GPU\":\n",
    "            gpu = False\n",
    "        else :\n",
    "            gpu = True\n",
    "        \n",
    "        seg_checkpoint_file = os.path.join(log_folder,\"segmentation_checkpoint.json\")\n",
    "        seg_checkpoint = load_checkpoint(seg_checkpoint_file)\n",
    "        segmented_files = seg_checkpoint.get(\"segmented_files\", [])\n",
    "        \n",
    "        image_files = []\n",
    "        for file in os.listdir(nuclei_folder):\n",
    "                if file.lower().endswith((\".tif\", \".tiff\")):\n",
    "                    image_files.append(os.path.join(nuclei_folder, file))\n",
    "        \n",
    "        seg_model = models.CellposeModel(gpu=gpu, pretrained_model=seg_directory_value)\n",
    "\n",
    "        display(HTML(\"<br><br>\"))\n",
    "        display(Markdown(\"## SEGMENTATION ##\"))\n",
    "        print(f\"\\nSegmentation device:\", seg_device)\n",
    "        print(f\"Loading segmentation model from: {seg_directory_value}\\n\")\n",
    "\n",
    "        seg_progress = widgets.IntProgress(min=0, max=len(image_files), description='Progress ',\n",
    "                                   style={'description_width': 'initial'}, layout=widgets.Layout(width='30%'))\n",
    "        display(widgets.HBox([seg_progress], layout=widgets.Layout(justify_content='center')))\n",
    "        \n",
    "        def loop(file_path, diameter):\n",
    "            base_name = os.path.basename(file_path)\n",
    "            name_without_ext = os.path.splitext(base_name)[0]\n",
    "            image = AICSImage(file_path).data[0,0]\n",
    "            masks, flows, styles = seg_model.eval(\n",
    "                image, \n",
    "                diameter=diameter,\n",
    "                channels=[0, 0], \n",
    "                normalize=True\n",
    "            )\n",
    "            if masks.max() > 0:\n",
    "                mask_save_path = os.path.join(masks_folder, name_without_ext + \".tif\")\n",
    "                imwrite(mask_save_path, masks.astype(np.uint32))\n",
    "                print(f\"Processed ans saved mask for : {base_name}\")\n",
    "            else:\n",
    "                print(f\"No cells detected in {base_name}\")\n",
    "            \n",
    "            return np.max(masks)\n",
    "        \n",
    "        for idx, fpath in enumerate(image_files, 1):\n",
    "            if fpath in segmented_files:\n",
    "                print(f\"{fpath} already segmented.\")\n",
    "                continue\n",
    "            try:\n",
    "                count = loop(fpath, dia)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed segmentation for {fpath} : {e}\")\n",
    "                continue\n",
    "            \n",
    "            segmented_files.append(fpath)\n",
    "            seg_checkpoint[\"segmented_files\"] = segmented_files\n",
    "            save_checkpoint(seg_checkpoint_file, seg_checkpoint)\n",
    "            seg_progress.value = idx\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "## CLASSIFICATION ##\n",
    "\n",
    "    if run_classification:\n",
    "\n",
    "        os.makedirs(predictions_output_dir, exist_ok=True)\n",
    "        \n",
    "        class_checkpoint_file = os.path.join(log_folder,\"classification_checkpoint.json\")\n",
    "        class_checkpoint = load_checkpoint(class_checkpoint_file)\n",
    "        classified_files = class_checkpoint.get(\"classified_files\", [])\n",
    "        \n",
    "        # Get image liste\n",
    "        myotube_files = [f for f in os.listdir(myotube_folder) if f.lower().endswith(('.tif', '.tiff'))]\n",
    "        prediction_data = []\n",
    "        \n",
    "        # Choose device\n",
    "\n",
    "        with open(config_path, 'r') as f:\n",
    "            config_dict = json.load(f)\n",
    "\n",
    "        if class_device == \"GPU\":\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            \n",
    "            if device.type == \"cuda\":\n",
    "                class_real_device = \"GPU\"\n",
    "            else :\n",
    "                class_real_device = \"CPU\"\n",
    "                print(\"CUDA is not avalaible - Classification will use CPU\")\n",
    "        else :\n",
    "            device = torch.device(\"cpu\")\n",
    "            class_real_device = class_device\n",
    "\n",
    "        # Load Classifier\n",
    "\n",
    "        display(HTML(\"<br><br>\"))\n",
    "        display(Markdown(\"## CLASSIFICATION ##\"))\n",
    "        print(f\"\\nClassification device:\", class_real_device)\n",
    "        print(f\"Loading classification model from: {class_directory_value}\\n\")\n",
    "\n",
    "        class_progress = widgets.IntProgress(min=0, max=len(myotube_files), description='Progress ', \n",
    "                                     style={'description_width': 'initial'}, layout=widgets.Layout(width='30%'))\n",
    "        display(widgets.HBox([class_progress], layout=widgets.Layout(justify_content='center')))\n",
    "        \n",
    "        checkpoint_model = torch.load(class_directory_value, map_location = device, weights_only = False)\n",
    "        model = checkpoint_model[\"model\"].to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        for idx, img_file in enumerate(sorted(myotube_files), 1):\n",
    "            if img_file in classified_files:\n",
    "                print(f\"{img_file} already classified.\")\n",
    "                continue\n",
    "            \n",
    "            img_path = os.path.join(myotube_folder, img_file)\n",
    "            mask_path = os.path.join(masks_folder, img_file)\n",
    "            if not os.path.exists(mask_path):\n",
    "                print(f\"No matching mask for {img_file}, skipping.\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Load Image\n",
    "                image_data = imread(img_path).astype(np.float32)\n",
    "                if image_data.ndim == 2:\n",
    "                    image_data = np.stack([image_data] * 3, axis=-1)\n",
    "                image_data = normalize_image(image_data, percentile_max)\n",
    "\n",
    "                # Save normalization\n",
    "                if save_normalization:\n",
    "                    os.makedirs(norm_dir, exist_ok=True)\n",
    "                    norm_image = img_as_ubyte(image_data)\n",
    "                    norm_path = os.path.join(norm_dir, img_file)\n",
    "                    imsave(norm_path, norm_image)\n",
    "                    print(f\"Normalized image saved for {img_file}\")\n",
    "                else:\n",
    "                    pass\n",
    "                        \n",
    "                # Load mask and calculate centroids\n",
    "                mask_data = imread(mask_path)\n",
    "                label_ids, centroids = compute_label_centroids(mask_data)\n",
    "                \n",
    "                # Prepare dataset and dataloader\n",
    "                dataset = PredictionDataset(\n",
    "                    image=image_data,\n",
    "                    labels=mask_data,\n",
    "                    label_ids=label_ids,\n",
    "                    centroids=centroids,\n",
    "                    half_patch_size=half_patch_size,\n",
    "                    device=device,\n",
    "                    config_dict=config_dict\n",
    "                )\n",
    "                dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "                image_preds = []\n",
    "                with torch.no_grad():\n",
    "                    for batch_tensor in dataloader:\n",
    "                        if batch_tensor is None or batch_tensor.size(0) == 0:\n",
    "                            continue\n",
    "                        outputs = model(batch_tensor)\n",
    "                        preds = outputs.argmax(dim=1)\n",
    "                        image_preds.extend(preds.cpu().numpy())\n",
    "                \n",
    "                # Save prediction image if selected\n",
    "                if save_prediction:\n",
    "                    base_name = os.path.splitext(img_file)[0]\n",
    "                    output_path = os.path.join(predictions_output_dir, f\"{base_name}_prediction.tif\")\n",
    "                    save_colored_predictions_downsample(\n",
    "                        labels=mask_data,\n",
    "                        predictions=image_preds,\n",
    "                        used_labels=label_ids,\n",
    "                        myotube_image=image_data,\n",
    "                        output_path=output_path,\n",
    "                        factor=downsampling_factor\n",
    "                    )\n",
    "                    print(f\"Prediction image saved for {img_file}\")\n",
    "                \n",
    "                # Calculate stats\n",
    "                pred_array = np.array(image_preds)\n",
    "                total_labels = len(pred_array)\n",
    "                num_ones = np.sum(pred_array == 1)\n",
    "                num_zeros = np.sum(pred_array == 0)\n",
    "                fusion_index = (num_ones / total_labels * 100.0) if total_labels else 0.0\n",
    "                prediction_data.append({\n",
    "                    \"Image Name\": base_name,\n",
    "                    \"Total Number of Nuclei\": total_labels,\n",
    "                    \"Nuclei In\": num_ones,\n",
    "                    \"Nuclei Out\": num_zeros,\n",
    "                    \"Fusion Index (%)\": fusion_index\n",
    "                })\n",
    "                \n",
    "                # Update checkpoint\n",
    "                classified_files.append(img_file)\n",
    "                class_checkpoint[\"classified_files\"] = classified_files\n",
    "                save_checkpoint(class_checkpoint_file, class_checkpoint)\n",
    "                class_progress.value = idx\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Failed to classify {img_file}: {e}\")\n",
    "                continue\n",
    "    \n",
    "        # Export results\n",
    "        predictions_df = pd.DataFrame(prediction_data)\n",
    "        output_file_path = os.path.join(parent_directory_value, \"Fusion_index.xlsx\")\n",
    "        predictions_df.to_excel(output_file_path, index=False)\n",
    "        \n",
    "        print(f\"\\nResults exported to: {output_file_path}\")\n",
    "        display(Markdown(\"<h3 style='text-align:center'>âœ… <b>Classification complete!</b></h3>\"))\n",
    "    \n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "#### SET-UP ####\n",
    "\n",
    "# Selection widgets\n",
    "# Folder\n",
    "folder_label = widgets.HTML(\n",
    "    value=\"<b>Folder with your images</b>\",\n",
    "    layout=widgets.Layout(margin=\"5px\")\n",
    ")\n",
    "folder_chooser = FileChooser('../', show_only_dirs=True)\n",
    "folder_hbox = widgets.HBox([folder_chooser],\n",
    "    layout=widgets.Layout(justify_content='center', width='100%')\n",
    ")\n",
    "folder_box = widgets.VBox(\n",
    "    [folder_label, folder_hbox],\n",
    "    layout=widgets.Layout(align_items='center', width='80%')\n",
    ")\n",
    "\n",
    "# Segmentation\n",
    "seg_label = widgets.HTML(\n",
    "    value=\"<b>Segmentation model file</b>\",\n",
    "    layout=widgets.Layout(margin=\"5px\")\n",
    ")\n",
    "seg_chooser = FileChooser('../')\n",
    "seg_hbox = widgets.HBox([seg_chooser],\n",
    "    layout=widgets.Layout(justify_content='center', width='100%')\n",
    ")\n",
    "seg_box = widgets.VBox(\n",
    "    [seg_label, seg_hbox],\n",
    "    layout=widgets.Layout(align_items='center', width='80%')\n",
    ")\n",
    "\n",
    "# Classification\n",
    "class_label = widgets.HTML(\n",
    "    value=\"<b>Classification model file</b> (Make sure config.json is in the same folder)\",\n",
    "    layout=widgets.Layout(margin=\"5px\")\n",
    ")\n",
    "class_chooser = FileChooser('../')\n",
    "class_hbox = widgets.HBox([class_chooser],\n",
    "    layout=widgets.Layout(justify_content='center', width='100%')\n",
    ")\n",
    "class_box = widgets.VBox(\n",
    "    [class_label, class_hbox],\n",
    "    layout=widgets.Layout(align_items='center', width='80%')\n",
    ")\n",
    "\n",
    "# Grouping blocks in a Vbox\n",
    "file_choosers_box = widgets.VBox(\n",
    "    [folder_box, seg_box, class_box],\n",
    "    layout=widgets.Layout(align_items='center', width='100%')\n",
    ")\n",
    "\n",
    "parent_directory = folder_chooser\n",
    "seg_directory = seg_chooser\n",
    "class_directory = class_chooser\n",
    "\n",
    "# Parameters widgets\n",
    "\n",
    "style={'description_width': '200px'}\n",
    "layout_widget={'width': '400px'}\n",
    "\n",
    "myotube_channel_widget = widgets.IntText(value=0, description='Myotube channel', style=style, layout=layout_widget)\n",
    "nuclei_channel_widget = widgets.IntText(value=1, description='Nuclei channel', style=style, layout=layout_widget)\n",
    "dia_widget = widgets.IntText(value=24, description='Cellpose diameter', style=style, layout=layout_widget)\n",
    "percentile_max_widget = widgets.FloatText(value=99.7, description='Normalization max percentile', style=style, layout=layout_widget)\n",
    "half_patch_size_widget = widgets.IntText(value=100, description='Half patch size', style=style, layout=layout_widget)\n",
    "batch_size_widget = widgets.IntText(value=512, description='Batch size', style=style, layout=layout_widget)\n",
    "split_images_widget = widgets.Checkbox(value=True, description='Split channels', style=style, layout=layout_widget)\n",
    "run_segmentation_widget = widgets.Checkbox(value=True, description='Run segmentation', style=style, layout=layout_widget)\n",
    "seg_device_widget = widgets.Dropdown(\n",
    "    options=['GPU', 'CPU'],\n",
    "    value='GPU',\n",
    "    description='Device for segmentation',\n",
    "    style=style,\n",
    "    layout=layout_widget\n",
    ")\n",
    "run_classification_widget = widgets.Checkbox(value=True, description='Run classification', style=style, layout=layout_widget)\n",
    "class_device_widget = widgets.Dropdown(\n",
    "    options=['GPU', 'CPU'],\n",
    "    value='GPU',\n",
    "    description='Device for classification',\n",
    "    style=style,\n",
    "    layout=layout_widget\n",
    ")\n",
    "save_normalization_widget = widgets.Checkbox(value=False, description='Save normalization', style=style, layout=layout_widget)\n",
    "save_prediction_widget = widgets.Checkbox(value=True, description='Save prediction', style=style, layout=layout_widget)\n",
    "downsampling_factor_widget = widgets.IntText(value=1, description='Downsampling factor', style=style, layout=layout_widget)\n",
    "\n",
    "params_box = widgets.VBox(\n",
    "    [\n",
    "        widgets.HTML(value=\"<h3>Adjust parameters and launch</h3>\"),\n",
    "        myotube_channel_widget,\n",
    "        nuclei_channel_widget,\n",
    "        dia_widget,\n",
    "        percentile_max_widget,\n",
    "        half_patch_size_widget,\n",
    "        batch_size_widget,\n",
    "        split_images_widget,\n",
    "        run_segmentation_widget,\n",
    "        seg_device_widget,\n",
    "        class_device_widget,\n",
    "        run_classification_widget,\n",
    "        save_normalization_widget,\n",
    "        save_prediction_widget,\n",
    "        downsampling_factor_widget\n",
    "    ],\n",
    "    layout=widgets.Layout(align_items='center', width='80%')\n",
    ")\n",
    "\n",
    "button_layout = widgets.Layout(width=\"200px\", height=\"50px\", margin=\"20px\")\n",
    "run_button = widgets.Button(description='Launch', layout=button_layout, button_style='success')\n",
    "resume_button = widgets.Button(description='Resume', layout=button_layout, button_style='warning')\n",
    "\n",
    "buttons_box = widgets.HBox([run_button, resume_button],\n",
    "    layout=widgets.Layout(justify_content='center', width='80%')\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "analysis_box = widgets.VBox([buttons_box, output],\n",
    "    layout=widgets.Layout(align_items='center', width='80%')\n",
    ")\n",
    "\n",
    "header = widgets.HTML(value=\"<h1 style='text-align:center'>Welcome to MyoFuse 1.0.0</h1>\")\n",
    "\n",
    "# Main Container\n",
    "main_ui = widgets.VBox(\n",
    "    [header, file_choosers_box, params_box, analysis_box],\n",
    "    layout=widgets.Layout(align_items='center', justify_content='center', width='100%')\n",
    ")\n",
    "\n",
    "# Callback for lauch button\n",
    "def on_run_button_click(b):\n",
    "    with output:\n",
    "        output.clear_output() \n",
    "        reset_checkpoints()\n",
    "        try:\n",
    "            # Recover parameters\n",
    "            myotube_channel = myotube_channel_widget.value\n",
    "            nuclei_channel = nuclei_channel_widget.value\n",
    "            dia = dia_widget.value\n",
    "            percentile_max = percentile_max_widget.value\n",
    "            half_patch_size = half_patch_size_widget.value\n",
    "            batch_size = batch_size_widget.value\n",
    "            split_images = split_images_widget.value\n",
    "            run_segmentation = run_segmentation_widget.value\n",
    "            seg_device =  seg_device_widget.value\n",
    "            run_classification = run_classification_widget.value\n",
    "            class_device = class_device_widget.value\n",
    "            save_normalization = save_prediction_widget.value\n",
    "            save_prediction = save_prediction_widget.value\n",
    "            downsampling_factor = downsampling_factor_widget.value\n",
    "\n",
    "            # Call analysis\n",
    "            run_entire_analysis(\n",
    "                 myotube_channel,\n",
    "                 nuclei_channel,\n",
    "                 dia,\n",
    "                 percentile_max,\n",
    "                 half_patch_size,\n",
    "                 batch_size,\n",
    "                 split_images,\n",
    "                 run_segmentation,\n",
    "                 seg_device,\n",
    "                 run_classification,\n",
    "                 class_device,\n",
    "                 save_prediction,\n",
    "                 save_normalization,\n",
    "                 downsampling_factor,\n",
    "                 parent_directory.value,\n",
    "                 seg_directory.value,\n",
    "                 class_directory.value\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(\"Erreur :\", e)\n",
    "\n",
    "# Callback for resume button\n",
    "def on_resume_button_click(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        print(\"Resuming analysis with existing checkpoints...\")\n",
    "\n",
    "        try:\n",
    "            # Recover parameters\n",
    "            myotube_channel = myotube_channel_widget.value\n",
    "            nuclei_channel = nuclei_channel_widget.value\n",
    "            dia = dia_widget.value\n",
    "            percentile_max = percentile_max_widget.value\n",
    "            half_patch_size = half_patch_size_widget.value\n",
    "            batch_size = batch_size_widget.value\n",
    "            split_images = split_images_widget.value\n",
    "            run_segmentation = run_segmentation_widget.value\n",
    "            seg_device =  seg_device_widget.value\n",
    "            run_classification = run_classification_widget.value\n",
    "            class_device = class_device_widget.value\n",
    "            save_normalization = save_prediction_widget.value\n",
    "            save_prediction = save_prediction_widget.value\n",
    "            downsampling_factor = downsampling_factor_widget.value\n",
    "            \n",
    "            run_entire_analysis(\n",
    "                myotube_channel,\n",
    "                nuclei_channel,\n",
    "                dia,\n",
    "                percentile_max,\n",
    "                half_patch_size,\n",
    "                batch_size,\n",
    "                split_images,\n",
    "                run_segmentation,\n",
    "                seg_device,\n",
    "                run_classification,\n",
    "                class_device,\n",
    "                save_prediction,\n",
    "                save_normalization,\n",
    "                downsampling_factor,\n",
    "                parent_directory.value,\n",
    "                seg_directory.value,\n",
    "                class_directory.value\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"Erreur :\", e)\n",
    "\n",
    "# Attach callbacks to buttons\n",
    "run_button.on_click(on_run_button_click)\n",
    "resume_button.on_click(on_resume_button_click)\n",
    "\n",
    "display(main_ui)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
